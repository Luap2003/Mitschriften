\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{Mathe 3}\\Mitschriften}
\author{\huge{Paul Glaser}}
\date{\today}

\begin{document}
\nocite{*}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
\chapter{Kurven, Bogenlänge und Parametrisierung von Kurven}
\section{Kurven im $\mathbb{R}^3$}
\dfn{Kurven}{Seien $I$ ein Intervall, und $f_1, \ldots, f_n: I \rightarrow \mathbb{R}$ stetige Funktionen. Dann heisst
$$
\begin{aligned}
f: \quad I & \rightarrow \mathbb{R}^n \\
t & \mapsto f(t)=\left(f_1(t), \ldots, f_n(t)\right)
\end{aligned}
$$
eine Kurve in $\mathbb{R}^n$. Die Kurve heisst differenzierbar, wenn alle Komponenten $f_k$ differenzierbar sind.}
\ex{}{\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.3]{Bilder/Spirale_Kurven.png}
    \caption{Die Grafik visualsiert die Kurve $f(t)=(\cos(t),\sin(t),t)$}
\end{figure}}
\dfn{Geschwindigkeit}{Seien $I$ ein Intervall, und $f: I \rightarrow \mathbb{R}^n$ eine differenzierbare Kurve. Dann heisst der Vektor
$$
f^{\prime}(t)=\left(f_1^{\prime}(t), \ldots, f_n^{\prime}(t)\right)
$$
der Geschwindigkeitsvektor zum Zeitpunkt $t$.\newline
Seine Länge $\left\|f^{\prime}(t)\right\|$ heisst Geschwindigkeit zum Zeitpunkt $t$.\newline
Ist $f^{\prime}\left(t_0\right) \neq 0$ für ein $t_0$, so heisst
$$
\begin{aligned}
g: & \mathbb{R} \rightarrow \mathbb{R}^n \\
g(t)= & f\left(t_0\right)+t f^{\prime}\left(t_0\right)
\end{aligned}
$$
die Tangente an $f$ in $f\left(t_0\right)$.}
\ex{Kreis}{Der Kreis ist beschrieben durch $f(t)=(r \cos t, r \sin t)$.\newline
Die Ableitung davon ist $$f^{\prime}(t)=(-r \sin t, r \cos t)$$ und damit die Geschwindigkeit $\sqrt{r^2\cdot \sin^2(t)+r^2\cdot\cos^2(t)} = |r| $. Die Tangente ist dann
$$
g(s)=f(t)+s f^{\prime}(t) .
$$}
\dfn{Winkel}{Seien $f: I \rightarrow \mathbb{R}^n$ und $g: I \rightarrow \mathbb{R}^n$ zwei Kurven mit $f\left(t_1\right)=g\left(t_2\right)$. Sind die Geschwindigkeitsvektoren $f^{\prime}\left(t_1\right), g^{\prime}\left(t_2\right) \neq 0$, dann ist der Winkel $\Theta$ zwischen den Kurven im Punkt $f\left(t_1\right)=g\left(t_2\right)$ definiert durch
$$
\cos \Theta=\frac{\left\langle f^{\prime}\left(t_1\right), g^{\prime}\left(t_2\right)\right\rangle}{\left\|f^{\prime}\left(t_1\right)\right\|\left\|g^{\prime}\left(t_2\right)\right\|}
$$}

\ex{}{
    Sei $f(x)= \frac{1}{4}x^2$ und $g(x)=(x-1)^3$. Dann ist der Schnittpunkt 
    \begin{align*}
        \frac{1}{4}x^2&=(x-1)^3\\
        x&=2
    \end{align*}
    $$
    \frac{d}{d x}\left((x-1)^3\right)=3(x-1)^2=3 \text{ für } x =2 
    $$
    $$
\frac{d}{d x}\left(\frac{x^2}{4}\right)=\frac{x}{2}=1 \text{ für } x=2
$$
\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.3]{Bilder/AngleOf2Curves.png}
    \caption{Eine visuelle Vorstellung dieses Winkels, des Schnittpunktes zweier Funktionen $f$ und $g$, und wie er durch die Tangenten berechenbar ist.}
\end{figure}
}

\section{Rektifizierbarkeit und Bogenlänge}
\dfn{Bogenlänge}{
    Die Kurve $f:[a, b] \rightarrow \mathbb{R}^n$ heißt rektifizierbar mit Bogenlänge $L \in \mathbb{R}$, wenn $\forall \varepsilon>0$ ein $\delta>0$ existiert, so dass für jede Unterteilung
$$
a=t_0<t_1<\ldots<t_r=b
$$
mit Feinheit $\leq \delta, d . h$.
$$
\left|t_i-t_{i+1}\right| \leq \delta \quad \forall \quad 0 \leq i \leq r
$$
gilt
$$
\left|P_f\left(t_0, \ldots, t_r\right)-L\right|<\varepsilon .
$$
}
\thm{Hilfssatz zur Berechnung der Bogenlänge}{
    Jede stetig differenzierbare Kurve $f:[a, b] \rightarrow \mathbb{R}^n$ ist rektifizierbar mit Bogenlänge
$$
L=\int_a^b\left\|f^{\prime}(t)\right\| d t
$$
}

\ex{}{\[
    f:\left[ 0,2\pi\right[
    \]
    \begin{align*}
        &f(t) = (r\cdot\cos(t),r\sin(t))\\
        &f^{\prime}(t) = (-r\sin(t),r\cos(t))\\
        &\left\|f^{\prime}(t)\right\| = \sqrt{r^2\sin^2(t)+r^2\cos^2(t)} = |r|\\
        &L = \int_0^{2\pi} |r| dt = 2\pi |r|
    \end{align*}
    }
\ex{Beispiel einer nicht rektifizierbaren Kurve}{
    \begin{align*}
        &f:\left[ 0,1\right[\to \mathbb{R^2}\\
        &f(t)=\begin{cases}
            (0,0) & t = 0\\
            (t,t\cdot \cos\left(\frac{1}{t}\right)) & t\neq 0
        \end{cases}
    \end{align*}
}

\thm{Hilfssatz}{
    Sei $f:[a, b] \rightarrow \mathbb{R}^n$ stetig differenzierbar. Dann gilt $\forall \varepsilon>0 \quad \exists \delta>0$ so dass
$$
\forall t, \tau \in[a, b] \text { mit } 0<|t-\tau|<\delta . \quad\left\|\frac{f(t)-f(\tau)}{t-\tau}-f^{\prime}(t)\right\| \leq \varepsilon
$$
\begin{figure}[H]
    \centering
    \includegraphics*[scale = 0.2]{Bilder/NonRectifiableCurve.png}
    \caption{Eine nicht rektifizierbare Kurve}
\end{figure}
}

\section{Parametrisierung von Kurven}
\dfn{Parametrisierung}{
    Sei $f:[a, b] \rightarrow \mathbb{R}^n$ eine (stetig diff.-bare) Kurve und $\varphi:[\alpha, \beta] \rightarrow[a, b]$ eine monoton steigende bijektive (stetig differenzierbare) Abbildung. Die Kurve
$$
g=f \circ \varphi:[\alpha, \beta] \rightarrow \mathbb{R}^n
$$
geht aus $f$ durch Parameterwechsel hervor.
}
\thm{}{
    Die Bogenlänge einer stetig differenzierbaren Kurve hängt nicht von der Parametrisierung ab.
}

\dfn{Parametrisierung nach Bogenlänge}{Sei $f:[a, b] \rightarrow \mathbb{R}^n$ eine (stetig diff.-bare) Kurve mit $f^{\prime}(t) \neq 0 \forall t \in[a, b]$. Dann ist die Funktion
$$
\varphi\left(t_1\right)=\int_a^{t_1}\left\|f^{\prime}(t)\right\| d t
$$
streng monoton und differenzierbar mit
$$
\left.\varphi^{\prime}(t)=\left\|f^{\prime}(t)\right\| \neq 0 \quad \forall t \in\right] a, b[
$$
und definiert eine Bijektion $\varphi:[a, b] \rightarrow[0, L]$ wobei $L$ die Bogenlänge von $f$ beschreibt. Die Umkehrabbildung $\Psi=\varphi^{-1}:[0, L] \rightarrow[a, b]$ liefert die Parametrisierung
$$
g=f \circ \Psi:[0, L] \rightarrow \mathbb{R}^n .
$$

Diese heißt Parametrisierung nach der Bogenlänge. Üblicherweise schreibt man $s \mapsto g(s)$.}

\ex{}{}

\thm{}{Sei $g:[0, L] \rightarrow \mathbb{R}^n$ Parametrisierung nach der Bogenlänge. Dann hat der Geschwindigkeitsvektor $T(s)=g^{\prime}(s)$ die Länge $\|T(s)\|=1$.}

\chapter{Funktionen im $\mathbb{R}^n$}
\section{Krümmung}
\dfn{}{Sei $g:[0, L]$ eine zweimal steigt differenzierbare Kurve, parametrisiert nach Bogenlänge. Dann heißt
$$
T(s)=g^{\prime}(s)
$$
Tangentialvektor der Kurve,
$$
\kappa=\kappa(s)=\left\|T^{\prime}(s)\right\|_2 = \left|\frac{d\psi}{ds}\right|
$$
heißt Krümmung der Kurve im Punkt $g(s)$ und
$$
N(s)=\frac{T^{\prime}(s)}{\kappa(s)}
$$
heißt Normalenvektor (definiert, wenn $\kappa(s) \neq 0$ ), also
$$
T^{\prime}(s)=\kappa(s) N(s)
$$}
\nt{Da $g$ parametrisiert ist, ist $\|T\| = 1$.\newline
 $N(s)$ ist einfach nur die normierte Zweite Ableitung, folgt aus der Eigenschaft das $\|T\| = 1$.
\begin{align*}
     1 & = \langle T(s),T(s) \rangle\\
     \frac{d}{ds} 1 &= \frac{d}{ds}\langle T(s),T(s) \rangle\\
     0 &= \frac{d}{ds}\sum t_i^2\\
     0 &= 2\sum t_i\cdot t_i^{'}\\
     0 &= \langle T(s),T^{'}(s) \rangle\\
 \end{align*}
 }
\dfn{Krümmungskreis}{Für ebene Kurven ist der Kreis mit Mittelpunkt $g(s)+\frac{1}{\kappa} N(s)$ und Radius $r=\frac{1}{\kappa}$, der Kreis, der die Kurve $g(s)$ am besten approximiert. Wir nennen diesen Kreis den Krümmungskreis.}
\nt{Da $\|N(s)\|=1$ gibt $r\cdot N(s)$ exakt die Radius Länge. Je größer die Kurve gekrümmt ist, desto kleiner wird der Kreis, während desto flacher die Kurve ist der Kreis auch flacher wird und sich perfekt anähert.}

\section{Kurven in $\mathbb{R}^3$}
\dfn{}{Sei $g:[0, L] \rightarrow \mathbb{R}^3$ eine Kurve, die nach Bogenlänge parametrisiert ist. Dann ist $N \perp T$. Wir wählen nun $B \in \mathbb{R}^3$ so, dass
$$
(T, N, B)
$$
eine orientierte Orthonormalmatrix bilden.\newline
Der Vektor $B$ heißt Binormalenvektor und das Tripel $(T, N, B)$ heißt Fresnelsches Dreibein.}
\thm{}{Die Ableitung des Binormalenvektors $B(s)$ kann durch
$$
B^{\prime}(s)=-\tau(s) N(s)
$$
beschrieben werden, wobei $\tau(s)$ eine bestimmte Funktion $R \rightarrow R$ ist. Wir nennen $\tau(s)$ die Torsion der Kurve im Punkt $g(s)$.}
\nt{
    \begin{align*}
        B(s) &= T(s)\times N(s)\\
        \frac{d B(s)}{ds}&=\frac{d(T(s) \times N(s))}{ds}\\
        &=\frac{d T(s)}{ds}N(s) \times N(s)+T(s) \times \frac{d N(s)}{d s}\\
        &=\kappa N(s) \times N(s)+T(s) \times \frac{d N(s)}{d s}\\
        &= T(s)\times \frac{d N(s)}{ds}\\
        &\text{$T(s)\implies$ orthogonal zu $T(s)$}\\
        &\text{da $r(s)\cdot r^{'}(s) = 0$ für alle $r$ mit $\|r\|=1$, muss $\frac{dB(s)}{ds}$ orthogonal zu $B(s)$ sein }\\
        &= \tau N(s)
    \end{align*}}
\section*{Funktionen auf $\mathbb{R}^n$}
\dfn{}{Mit $f: D \subset \mathbb{R}^n \rightarrow \mathbb{R}$ ordnen wir jedem Element von $D \subset \mathbb{R}^n$ einen reellen Wert zu.
Die Menge $\Gamma_f:=\{(x, y) \in D \times \mathbb{R} \mid f(x)=y\}$ ist der Graph von $f$.}
\dfn{Niveaumenge}{Sei $f: D \rightarrow \mathbb{R}$ und $c \in \mathbb{R}$. Die Menge aller Punkte $x$ für die $f(x)=c$,
$$
N_c(f)=\{x \in D \mid f(x)=c\},
$$
heißt Niveaumenge von $f$ zum Niveau $c$.}
\nt{Man erhält den Contourplot durch mehrfaches plotten von verschiedenen Niveaumengen.}
\begin{figure}[H]
    \centering
    \includegraphics[scale = 1]{Bilder/F.pdf}
    \quad
    \includegraphics[]{Bilder/F_countour.pdf}
    \caption{Die Funktion $f(x_1, x_2) = x_1^2  +x_2^2$ und ihr Contourplot}
\end{figure}
\dfn{Offener und abgeschlossener Ball}{Sei $a \in \mathbb{R}^n$ und $r>0$. Dann ist die Menge
$$
B_r(a):=\left\{x \in \mathbb{R}^n \mid\|x-a\|_2<r\right\}
$$
ein offener Ball mit Radius $r$ und
$$
\overline{B_r(a)}:=\left\{x \in \mathbb{R}^n \mid\|x-a\|_2 \leq r\right\}
$$
ein abgeschlossener Ball mit Radius $r$.}
\dfn{Offen und abgeschlossen}{Sei $U \subset \mathbb{R}^n$ eine Teilmenge.\newline
$U$ heißt offen, falls $\forall a \in U: \exists \varepsilon>0$ so dass $B_{\varepsilon}(a) \subset U$.\newline
Eine Teilmenge $A \subset \mathbb{R}^n$ heißt abgeschlossen, wenn $\mathbb{R}^n \backslash A$ offen ist.}
\nt{$B_r(a)$ ist offen und $\overline{B_r(a)}$ ist abgeschlossen.}
\dfn{beschränkt und kompakt}{Eine Teilmenge $D \subset \mathbb{R}^n$ heißt beschränkt, wenn es ein $r>0$ gibt, so dass $D \subset B_r(0)$. Eine abgeschlossene und beschränkte Menge $K \subset \mathbb{R}^n$ heißt kompakt.}
\dfn{}{Sei $D \subset \mathbb{R}^n$ eine Teilmenge.
$$
\stackrel{\circ}{D}:=\left\{x \in \mathbb{R}^n \mid \exists \varepsilon>0: B_{\varepsilon}(x) \subset D\right\}
$$
ist die Menge der inneren Punkte von $D$. Mit
$$
\bar{D}:=\left\{x \in \mathbb{R}^n \mid B_{\varepsilon}(x) \cap D \neq \emptyset \forall \varepsilon>0\right\}
$$
bezeichnen wir den Abschluss von $D$. Der Rand von $D$ ist
$$
\partial D=\bar{D} \backslash \stackrel{\circ}{D}
$$}
\nt{noch keine Ahnung was ich dazu sagen soll :)}
\ex{}{$$
B_r(a) \text { ist der Abschluss von } B_r(a) \text { und } \partial B_r(a)=\left\{x \in \mathbb{R}^n \mid\|x-a\|_2=r\right\} \text { ist die Kugeloberfläche }
$$}
\section{Differentiation}
\dfn{stetig}{Sei $D \subset \mathbb{R}^n, f: D \rightarrow \mathbb{R}$ eine Funktion.
Die Funktion $f$ heißt stetig in $a \in D \subset \mathbb{R}^n$, wenn für alle $\varepsilon>0$ ein $\delta>0$ existiert, so dass
$$
|f(x)-f(a)|<\varepsilon \quad \forall x \in D
$$
mit $\|x-a\|_2<\delta$}
\thm{}{Summe, Produkte und Quotienten (falls definiert) stetiger Funktionen sind stetig.}
\dfn{Partiell differenzierbar}{Sei $f: U \rightarrow R, a=\left(a_1, \ldots, a_n\right) \in U$
Dann heißt $f$ in a partiell nach $x_i$ differenzierbar, wenn die Funktion in einer Variablen
$$
x_i \mapsto f\left(a_1, \ldots, a_{i-1}, x_i, a_{i+1}, \ldots, a_n\right)
$$
nach $x_i$ differenzierbar ist. Dann heißt
$$
\frac{\partial f}{\partial x_j}(a):=\lim _{h \rightarrow 0} \frac{f\left(a_1, \ldots, a_{i-1}, a_i+h, a_{i+1}, \ldots, a_n\right)-f\left(a_1, \ldots, a_{i-1}, a_i, a_{i+1}, \ldots, a_n\right)}{h}
$$
die partielle Ableitung von $f$ nach $x_i$.}
\nt{Die komplexe Version der Ableitung vom Ein-dimensionalem falls
$$
\frac{df}{dx}(x) = \lim_{h\to \infty}\frac{f(x+h)-f(x)}{h}
$$}
\dfn{Gradient}{Ist $f: U \rightarrow \mathbb{R}, U$ offen, in jedem Punkt nach allen Variablen partiell differenzierbar, dann heißt $U$ partiell differenzierbar auf $U$. Der Vektor
$$
\nabla f(a):=(\operatorname{grad} f)(a):=\left[\begin{array}{lll}
\frac{\partial f}{\partial x_1}(a) & \ldots & \frac{\partial f}{\partial x_n}(a)
\end{array}\right]
$$
heißt Gradient von $f$ im Punkt $a \in U$.}
\ex{}{Sei $f(x,y) = (x^2+y^2, x\cdot y^2)$. Dann ist 
\begin{align*}
    \nabla f(x,y)&=(\operatorname{grad} f)(x,y):=\left[\begin{array}{ll}
        \frac{\partial f}{\partial x}(x,y) ,& \frac{\partial f}{\partial y}(x,y)
        \end{array}\right]\\
        &=(2x,2xy)
\end{align*}
}
\dfn{Hesse-Matrix}{Die Matrix
$$
\operatorname{Hess}(f)=\left(\frac{\partial^2 f}{\partial x_i \partial x_j}\right)_{i j}=\left[\begin{array}{cccc}
\frac{\partial^2 f}{\partial x_1^2} &  \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\vdots & & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots &\frac{\partial^2 f}{\partial x_n^2} 
\end{array}\right]
$$
heißt Hesse-Matrix.}
\thm{}{Sei $f: U \rightarrow \mathbb{R}$ zweimal stetig differenzierbar, dann gilt
$$
\frac{\partial^2 f}{\partial x_i \partial x_j}=\frac{\partial^2 f}{\partial x_j \partial x_i} .
$$
Das heißt unter diesen Voraussetzungen ist die Hesse-Matrix symmetrisch.}
\ex{}{Sei $f(x,y)=\sqrt{x^2(1-y)}$, dann ist 
$$\operatorname{Hess}(f) = \left[\begin{array}{ccc}
    6x\cdot y^2 & 4x\cdot y^3\cdot z^2\cdot c^2 & 0\\
    4x\cdot y^3\cdot z^2 &  
\end{array}\right]$$
}





\chapter{Taylorformel und Extremstellen}
\section{Kettenregel}
\dfn{}{Sei $ U \subset \mathbb{R}^n$ offen, $f: U \rightarrow \mathbb{R}^m$ $f(u) \subset V \subset \mathbb{R}^m$ und $V$ offen, sowie $g: V \rightarrow \mathbb{R}$ und $h=g \circ f$ 
Die Koordinaten in $U$ bezeichnen wir mit $x_i$, die in $V$ mit $x_j$. Dann gilt
$$
\frac{\partial h}{\partial x_i}(x)=\sum_{j=1}^m \frac{\partial g}{\partial y_j}\left(f(x)\right) \frac{\partial f_j}{\partial x_i}(x)
$$}
\nt{Die Kettenregel lässt sich über herleiten durch nutzen der Taylor-Entwicklung Erster Ordnung:\newline
Seien $f,g,h$ definiert wie oben, dann ist
\begin{equation}\label{eq:1}    
g(y) \approx g(f(x))+\sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x))\left(y_j-f_j(x)\right).
\end{equation}
Für $f$ in der Nähe von $x$ erhält man:
$$
f_i(x+\Delta x) \approx f_i(x)+\sum_{k=1}^n \frac{\partial f_i}{\partial x_k}(x) \Delta x_k
$$
Da Eq:\ref*{eq:1} $h$ beschreibt und man an der Entwicklungsstelle $h(x+\Delta x)$ interessiert sind, setzt  man $y = f(x+\Delta x)$ in die Taylor-Entwicklung von $g$ ein
\begin{align*}
h(x+\Delta x) &\approx g(f(x+\Delta x))+\sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x))\left(f_j(x+\Delta x)-f_j(x)\right)\\
h(x)+\Delta h(x)&\approx g(f(x))+\sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x))\left(\sum_{k=1}^n \frac{\partial f_j}{\partial x_k}(x) \Delta x_k\right)\\
\Delta h(x) &\approx \sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x))\left(\sum_{k=1}^n \frac{\partial f_j}{\partial x_k}(x) \Delta x_k\right)\quad \text{ da $h(x)=g(f(x))$}\\
\frac{\Delta h(x)}{\Delta x_i} &\approx \sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x))\left(\sum_{k=1}^n \frac{\partial f_j}{\partial x_k}(x) \frac{\Delta x_k}{\Delta x_i}\right)\\
\frac{\partial h}{\partial x_i}(x)=\lim _{\Delta x_i \rightarrow 0} \frac{\Delta h(x)}{\Delta x_i} &= \sum_{j=1}^m \frac{\partial g}{\partial y_j}(f(x)) \frac{\partial f_j}{\partial x_i}(x)\quad \text{ da $\frac{\Delta x_k}{\Delta x_i}$ wird 0 für alle $k\neq i$}\\
\end{align*}
}
\ex{}{Sei $f(r,\phi) = (r\cdot \cos(\phi),r\cdot \sin(\phi))$, dann ist 
$$J_f = \operatorname*{D}f = \left[\begin{array}{cc}
    \cos(\phi) & -r\cdot \sin(\phi)\\
    \sin(\phi) & r\cdot \cos(\phi)
\end{array}\right]$$
Sei $g(x,y) = x^2+ y^2$, dann ist $\operatorname*{D}g = (2x,2y)$.\newline
Sei $h = g\circ f$, dann ist gilt
$$h(r,\phi) = (r\cdot \cos(\phi))^2+(r\cdot \sin(\phi))^2 = r^2 $$
Von hier ist leicht zu sehen, dass 
$$\frac{\partial h}{\partial r} = 2r\quad \frac{\partial h}{\partial \phi} = 0$$
\begin{align*}
    \operatorname*{D} h(r,\phi) &= \operatorname*{D}g(f(r,\phi))\cdot \operatorname*{D}f\\
    &= (2 r \cos f, 2 r \sin \phi) \cdot \operatorname*{D} f(r, \phi) \\
    & = (2 r, 0)
\end{align*}
Es kann auch über die Formel berechnet werden
\begin{align*}
    \frac{\partial h}{\partial r}(r,\phi) &= \frac{\partial g}{\partial x}(f(r,\phi))\frac{\partial f_1}{\partial r}(r,\phi)+ 
    \frac{\partial g}{\partial y}(f(r,\phi))\frac{\partial f_2}{\partial r}(r,\phi)\\
    &= 2\cdot (r\cos(\phi))\cos(\phi)+2\cdot(r\sin(\phi))\sin(\phi)\\
    &=2r
\end{align*}
\begin{align*}
    \frac{\partial h}{\partial \phi}(r,\phi) &= \frac{\partial g}{\partial x}(f(r,\phi))\frac{\partial f_1}{\partial \phi}(r,\phi)+ 
    \frac{\partial g}{\partial y}(f(r,\phi))\frac{\partial f_2}{\partial \phi}(r,\phi)\\
    &=2\cdot(r\cdot \cos(\phi))\cdot(-r\sin(\phi))+2\cdot(r\cdot \sin(\phi))\cdot(r\cos(\phi))\\
    &=0
\end{align*}
Man erhält das gleiche Ergebnis
    }











\section{Richtungsableitungen}
\dfn{}{Sei $U \subset \mathbb{R}^n$ offen und $f: U \rightarrow \mathbb{R}, a \in U$ und $v \in \mathbb{R}^n$ mit $\|v\|=1$, Dann heißt
$$\left(D_v f\right)(a)=\lim _{h \rightarrow 0} \frac{f(a+h \cdot v)-f(a)}{h}$$
Richtungsableitung von $f$ in Richtung $v$.}
\thm{}{Sei $f: U \rightarrow \mathbb{R}, U \in \mathbb{R}^n$ offen, total und differenzierbar in $a$. Dann gilt
$$
(D_v f)(a)=\langle(\operatorname{grad} f)(a), v\rangle \text {. }
$$
Insbesondere: Für $v\in g^{n-1}:=\left\{v e \mathbb{R}^n \mid\|v\|=1\right\}$ ist die Richtungsableitung maximal genau dann, wenn de fradiar (gradf) (a) in die Gluide Ridehueg wie V zeigt}
\section{Taylorpolynome}
\dfn{Multiindex}{$\alpha=\left(\alpha_1, \ldots, \alpha_n\right) \in \mathbb{N}^n$ nennen wir einen Multiindex.
$|\alpha|=\alpha_1+\ldots+\alpha_n$ heißt Totalgrad von $\alpha$. Wir setzen $x^\alpha=x_1^{\alpha_1} x_n^{\alpha_n}$ Damnn bezeichnet
$$
\operatorname*{D}^\alpha f:=\frac{\partial^{|\alpha|} f}{\partial x^\alpha}=\frac{\partial^{|\alpha|} f}{\partial x_1^{\alpha_1} \ldots \partial x_n^{\alpha_n}}
$$
Die $\alpha$-te partielle Ableitung.}
\ex{}{\begin{align*}
    & \alpha=(1,2,3) \quad\left|\alpha\right|=1+2+3=6 \\
    & \operatorname*{D}^\alpha f=\frac{\partial^6 f}{\partial x_1 \partial x_2^2 \partial x_3^3}
    \end{align*}}
\dfn{Taylorpolynome}{Sei $U \subset \mathbb{R}^n$ offen, $a \in U$. sei $f: u \rightarrow \mathbb{R}$ $k$-mal stetig partiell differenzierbar. Dann heißt das polynom
$$
\sum_{|\alpha| \leq k} \frac{\partial|\alpha| f}{\partial x|\alpha|}(a) \cdot \frac{(x-a)^\alpha}{\alpha !}
$$
das Taylorpolynom $k$-ter Ordnung vou $f$ in a.}
\nt{Eine hübsche andere Formel für den Fall $U\subset \mathbb{R}^2$ und $f:U\to \mathbb{R}$, ist über die Summe der binomischen Formeln:
$$f(x) = f+\sum_{i=1}^k\frac{1}{i!}\left(\frac{\partial f}{\partial x}(x-a)+\frac{\partial f}{\partial y}(y-a)\right)^i$$ mit $f$ evaluiert an der Stelle $a$. Der Zussamenhang folgt aus der Beziehung zum Binomialkoeffizienten, da man bei $\alpha$ $k$ Elemente aus $n$ auswählt.}
\ex{}{
Sei $f(x,y) = e^{-x^2-y^2}$ und der Entwicklungspunkt $a=(1,1)$, dann sind 
$$
\frac{\partial f}{\partial x}=-2 x e^{-x^2-y^2}\quad 
\frac{\partial f}{\partial y}=-2 y e^{-x^2-y^2}
$$
Die ersten partiellen Ableitungen und 
$$
\frac{\partial^2 f}{\partial x^2}=\left(4 x^2-2\right) e^{-x^2-y^2} \quad \frac{\partial^2 f}{\partial x\partial y}=4 x y e^{-x^2-y^2}\quad
\frac{\partial^2f}{\partial y^2}=\left(4 y^2-2\right) e^{-x^2-y^2}
$$
Daraus folgt das Das Taylorpolynom erster Ordnung 
$$
f(x) = f(a) + \frac{\partial f}{\partial x}(a)\cdot(x-a) + \frac{\partial f}{\partial y}(a)\cdot (y-a) = 1
$$
Das Taylorpolynom 2-ter Ordnung ist 
\begin{align*}
    f(x) &= f(a) + \frac{\partial f}{\partial x}(a)\cdot(x-a) + \frac{\partial f}{\partial y}(a)\cdot (y-a)\\
    &+ \frac{1}{2}\left(\frac{\partial^2 f}{\partial x^2}(a)\cdot (x-a)^2+\frac{\partial^2 f}{\partial x\partial y}(a)\cdot (x-a)(y-a)
    +\frac{\partial^2f}{\partial y^2}(a)\cdot (y-a)^2\right)\\
    &= 1-x^2-y^2
\end{align*}
\begin{figure}[H]
    \centering
    \includegraphics*[scale=0.15]{Bilder/Taylopolynome.png}
    \caption{Die Funktion $f(x, y) = e^{-x^2 - y^2}$ und die Taylorpolynome erster und zweiter Ordnung um den Entwicklungspunkt $(0,0)$.}
\end{figure}
}
\section{Extrempunkte, Maxima, Minima}
\dfn{}{Sei $f: u \rightarrow \mathbb{R}, U \subset \mathbb{R}^n$.
$f$ hat ein lokales 
(lokales Muimun), wenn ein Ball
$Br (a) \subset U$ existiert, so dass $\left.f\right|_{B_r(a)}$
in $a$ das Maximum (Minimun) hat.\newline
$f$ hat ein lokales Extrema, wenn eine der beiden Bediengungen eintritt.}
\mlenma{}{Die Matrix $A=A^{\top} \in \mathbb{R}^{n\times n}$ ist positiv definit, falls
\begin{align*}
    &x^{\top} A x>0 \quad \forall x \in \mathbb{R}^n \backslash\{0\} \text {. }\\
    &\iff \text{ alle Eigenwerte der Matrix  $> 0$ sind}
\end{align*}
}
\thm{Minima und Maxima}{Sei $U \subset \mathbb{R}^k$ offen: $f: U \rightarrow \mathbb{R}$ zweimal stetig partiell differenzierbar
\begin{itemize}
    \item[1] Notwendig dafür, dass $f$ in $a \in U$ ein lokales Extrema hat, ist dass
    $$
    \frac{\partial f}{\partial x_1}(a)=\ldots=\frac{\partial f}{\partial x_n}(a)=0
    $$Ist die notwendige Bedingung erfüllt, dann ist hinreichend für ein lokales Minimum, dass die Matrix
    $$
    A=\operatorname{Hess}(f)(a)=\left(\frac{\partial^2 f}{\partial x_i \partial x_j}(a)\right)_{i j}
    $$
    positiv definit ist. Ist $A$ negativ definit dann liegt ein lokales Maximun vor.
\end{itemize} 
}
\ex{}{
    $$
\begin{aligned}
& f(x, y)=x^2+y^2 \quad \frac{\partial f}{\partial x}=2 x=0 \\
& \frac{\partial f}{\partial y}=2 y=0
\end{aligned}
$$
$\Rightarrow(0,0)$ ist der einzige Kandidat für ein lokales Extrema
$$
\operatorname*{Hess}(f)(a)=\left[\begin{array}{ll}
2 & 0 \\
0 & 2
\end{array}\right]>0
$$
Folglich hat die Funktion in (0,0) ein lokales Minima.
}
\chapter{Hyperflächen und Satz über implizite Funktionen}
\section{Hyperflächen}
\dfn{}{Sei $f:\mathbb{R}^n \to \mathbb{R}$ eine differenzierbare Funktion. Dann heißt ihre Nullstellenmenge
$$N(f):=N_0(f)=\{a\in \mathbb{R}^n\mid f(a)=0\}$$
die durch $f$ definierte Hyperfläche.
}
\ex{}{$x^2+y^2+z^2-1 = 0$  ist eine Kugel, siehe abb. \ref*{fig:kreis}}
\begin{figure}[H]
    \centering
    \includegraphics*{Bilder/Kugel.pdf}
    \caption{Eine 3-dimensionale Kugel mit dem Radius 1}
    \label{fig:kreis}
\end{figure}
\section{Tangentialraum}
\dfn{}{Sei $X=N(f)$, $f$ stetig differenzierbar, eine Hyperfläche und $a \in X$. Dann ist
$$
f(x)=f(a)+\sum_{j=1}^n \frac{\partial f}{\partial x_j}(a)\left(x_j-a_j\right)+\sigma(\|x-a\|)
$$
die erste Taylorformel (zum Landau Syubol $\sigma(1 )$)
\footnote{Ich denke das hier einfach der Rest Term eines Taylorpolynoms gemeint ist und das dieser langsamer wächst als $\|\|x-a\|\|\iff o(\|\|x-a\|\|)$}, so heißt
$$
T_a x=\left\{x \in \mathbb{R}^n \mid \sum_{j=1}^n \frac{\partial f}{\partial x_j}(a)\left(x_j-a\right)=0\right\}
$$
der Tangentialraum von $X$ im Punkt $a$}
\cor{Glatt oder Singulär}{$T_a X$ ist der zu $\operatorname{grad} f(a)$ orthogonale Untervektorraum:
$$
\left\{x \in \mathbb{R}^n \mid\langle\operatorname{grad} f(a), x\rangle=0\right\}
$$
Falls $\operatorname{grad} f(a) \neq 0$, ist $T_a X$ eine Hyperebene und $x$ ist glatt in a. Andernfalls ist $T_a X$ der gesamte Raum und $x$ ist singulär in a.

In dieser überarbeiteten Formulierung beschreibt der Tangentialraum $T_a X$ den Untervektorraum, der orthogonal zum Gradienten von f an der Stelle a ist. Der Gradient von f, oft als $\operatorname{grad} f(a)$ bezeichnet, gibt die Richtung des steilsten Anstiegs der Funktion f an der Stelle a an.

Wenn der Gradient von f an der Stelle a ungleich Null ist, bildet der Tangentialraum eine Hyperebene, und die Funktion ist glatt (d. h. differenzierbar) an der Stelle a. Wenn der Gradient jedoch gleich Null ist, entspricht der Tangentialraum dem gesamten Raum, und die Funktion hat an der Stelle a einen singulären Punkt (d. h. sie ist möglicherweise nicht differenzierbar oder hat einen kritischen Punkt).}
\section{Satz über implizite Funktionen}
\dfn{}{Sei $U \subset \mathbb{R}^n$ offen, $f: U \rightarrow \mathbb{R}$ mal stetig differenzierbar und
\begin{equation}
a=\left(a_1, \ldots, a_{n-1}, a_n\right) \in N(f),
\end{equation}
gilt $\frac{\partial f}{\partial x_n}(a) \neq 0$, dann existieren offene Umgebungen $V^{\prime} \subset \mathbb{R}^{n-1}$ von $\left(a_1, \ldots, a_{n-1}\right)=: a^{\prime}$ und $V^{\prime \prime} \subset \mathbb{R}$ von $a_n=: a^{\prime \prime}$ mit $V^{\prime} \times V^{\prime \prime} \subset U$ und es existiert eine Funktion $g: V^{\prime} \rightarrow V^{\prime \prime}$ und $g\left(a^{\prime}\right)=a^{\prime \prime}$ und
\begin{enumerate}
    \item $f\left(x_1, \ldots, x_{n-1}, g\left(x_1, \ldots, x_{n-1}\right)\right)=0$ $\forall x^{\prime}=\left(x_1, \ldots, x_{n-1}\right) \in V^{\prime}$ und
    \item $\forall\left(x^{\prime}, x^{\prime \prime}\right) \in\left(V^{\prime} \times V^{\prime \prime}\right) \cap N(f)$ gilt $x^{\prime \prime}=x_n=g\left(x^{\prime}\right)$.
\end{enumerate}
$g$ ist lokal stetig differenzierbar und
\begin{equation}
\frac{\partial g}{\partial x_i}\left(a^{\prime}\right)=-\frac{\partial f}{\partial x_i}(a) / \frac{\partial f}{\partial x_n}(a) \quad \text{für } i=1, \ldots, n-1 .
\end{equation}}
\nt{Grundlegend besagt der Satz, dass wenn eine Gleichung in der Form $f(x_1, x_2, \ldots, x_n) = 0$ eine Funktion implizit definiert und bestimmte Regularitätsbedingungen erfüllt sind, dann kann man die Ableitungen dieser impliziten Funktion berechnen, ohne sie explizit zu lösen.}
\chapter{Integration im $\mathbb{R}^n$}
\section{Doppelintegral}
\dfn{}{Der Grenzwert
$$
\lim_{\substack{h \to \infty \\ \Delta A_k \to 0}} \sum_{k=1}^h f(x_k, y_k) \Delta A_k
$$
wird (falls er existiert) als Doppelintegral bezeichnet und durch 
$$
\iint_A f(x, y) dA
$$
gekennzeichnet.}
\nt{Angenommen, die Fläche A ist in M Reihen und N Spalten unterteilt, 
wobei die Breite der iten Spalte $\Delta \mathrm{x}_{-}$i und die Höhe der j-ten Reihe $\Delta \mathrm{y}_{-}$j ist.\newline
Die Fläche der kleinen rechteckigen Teilfläche an der Position (i, j) ist dann $\Delta \mathrm{A}_{-} \mathrm{ij}=\Delta \mathrm{x}_{-} \mathrm{i} \Delta \mathrm{y}_{-} \mathrm{j}$.
$$S=\sum_{i=1}^M \sum_{j=1}^N f\left(x_{i j}, y_{i j}\right) \Delta A_{i j}$$
Der Grenzwert dieser Flächen ist dann das Integral, in Abb: \ref{fig:Doppelintegral} ist eine solche Teilfäche zu sehen
$$
\iint_A f(x, y) d A=\lim _{\substack{\Delta x_i, \Delta y_j \rightarrow 0 \\ M, N \rightarrow \infty}} \sum_{i=1}^M \sum_{j=1}^N f\left(x_{i j}, y_{i j}\right) \Delta A_{i j}
$$
Ich finde diese Formel etwas intuitiver, da klar ist was $k$ und $\delta A_k$ sind. 
\newline
In Bezug auf ihre Integrationsgrenzen ergibt sich 
$$
\iint_A f(x, y) d A=\int_a^b \int_c^d f(x, y) d y d x
$$
    \begin{figure}[H]
        \centering
        \includegraphics*[scale=0.1]{Bilder/Surface_integral1.png}
        \caption{
            Eine Illustration eines einzelnen Oberflächenelements. Diese Elemente werden durch den Integrierungsprozess unendlich klein gemacht, um sich der Oberfläche anzunähern.}
        \label{fig:Doppelintegral}
        \end{figure}
        $$
        \iint_A f(x, y) d t=\int_{x=a}^b \underbrace{\int_{y=f_u(x)}^{f_0(x)} f(x, y) d y}_{\text {Inneres Integral }} d x
        $$
        Das innere Integral wird für unendlcih viele infintisemal wenig aus einanderliegernde $x$ berechnet.
        Dann werden all diese Integrale, genau wie bei einem einfachen Integral Funktionswerte, integriert.
        \newline
        In der Abb \ref*{fig:Doppelintegral_innere} ist bspw. das innere Integral für $x=0$ zu sehen.
    \begin{figure}[H]
        \centering
        \includegraphics*[scale=0.5]{Bilder/DoppelIntegralInnere.png}
        \caption{
            Die Funktion $f(x,y)=x^2+y^2$ und eine herausgeschnittene Scheibe $\int f(0,y)dy$}
        \label{fig:Doppelintegral_innere}
        \end{figure}        
}
\section{Berechnung eines Doppelintegrals unter Verwendung kartesischer Koordinaten}
\nt{\begin{itemize}
    \item Ein Doppelintegral wird von innen nach außen integriert, d.h. zuerst bezüglich der Variablen $y$ und dann bezüglich der Variablen $x$. Die Integrationsgrenzen des inneren Integrals sind dabei von $x$ abhängige Funktionen, während die des äußeren Integrals konstant oder von einer anderen Variablen abhängig sein können.
    \item -Die Reihenfolge der Integration ist normalerweise durch die Reihenfolge der Differentiale im Doppelintegral festgelegt. Sie sind jedoch austauschbar, wenn alle Integrationsgrenzen konstant sind (rechteckiges Integrationsgebiet).
\end{itemize}
}
\ex{}{
$$
B=\left\{(x, y): x^2+y^2 \leqslant r^2 ; x \geqslant 0, y \geqslant 0,r \in \mathbb{R}\right\}
$$
Es soll das Doppelintegral 
$$
\iint_B x \cdot y d B
$$ berechnet werden.
\begin{figure}[H]
    \centering
    \includegraphics*[scale=0.5]{Bilder/Kreis_Surface_Integral.png}
    \caption{
        Die Funktion $f(x,y)=x\cdot y$ für die Menge $B$}
    \label{fig:Kugel_Doppelintegral_Surface}
    \end{figure}  
In Abb. \ref*{fig:Kugel_Doppelintegral_Surface} ist die Funktion zu sehen, das Surface-Integral berechnet das Volumen unter dieser Funktion.
$$
\begin{aligned}
& B: a=0, b=R \\
& f_u(x)=0, f_0(x)=\sqrt{R^2-x^2} \\
& \iint_B x y d B=\int_0^R\left[\int_0^{\sqrt{R^2-x^2}} x y d y\right] d x \\
& =\left.\int_0^R x\cdot \frac{y^2}{2}\right|_0 ^{\sqrt{R^2-x^2}} d x \\
& =\int_0^R x\left(\frac{R^2-x^2}{2}\right) d x \\
& =\int_0^R \frac{R^2 x}{2}-\frac{x^3}{2} d x \\
& =\left[\frac{R^2 x^2}{4}-\frac{x^4}{8}\right]_0^R=\frac{R^4}{4}-\frac{R^4}{8} \\
& =\frac{R^4}{8} \\
&
\end{aligned}
$$
}
\nt{Beim Übergang von kartesischen Koordinaten $(x, y)$ zu Polarkoordinaten $(r, \varphi$ gelten die Transformationsgleichungen:
\begin{equation}
\begin{aligned}
x &= r \cos \varphi \\
y &= r \sin \varphi \\
dA &= r \, dr \, d\varphi
\end{aligned}
\end{equation}
Doppelintegral in Polarkoordinaten:
\begin{equation}
\iint_A f(x, y) \, dA = \int_{\varphi=\varphi_1}^{\varphi_2} \int_{r=r_i(\varphi)}^{r_a(\varphi)} f\left(r \cos \varphi, r \sin \varphi\right) \, r \, dr \, d\varphi
\end{equation}
\begin{enumerate}
    \item Innere Integration nach $r$ (Radialkoordinate)
    \item Äußere Integration nach $\varphi$
\end{enumerate}
Wir erhalten
$$
\begin{aligned}
\iint_B x y d B & =\int_0^{\pi / 2}\left[\int_0^R r \cos \varphi r \sin \varphi r d r\right] d \varphi \\
& =\int_0^R \left[\int_0^{\frac{\pi}{2}} r^3\cos \varphi \sin \varphi d \varphi\right] d r \\
& =\int_0^R r^3 \frac{1}{2}\left[\sin ^2 \varphi\right]_0^{\frac{\pi}{2}} d r \\
& =\frac{1}{2} \int_0^R r^3 d r=\frac{R^4}{8}
\end{aligned}
$$
}


\section{Transformation der Variablen}
\dfn{}{
    \begin{itemize}
        \item Durch die Funktion
        $$
        \begin{aligned}
        & x=\varphi(\tilde{x}, \tilde{y}) \\
        & y=\psi(\tilde{x}, \tilde{y})
        \end{aligned}
        $$
        werde der Bereich $\widetilde{\beta}$ der $\tilde{x}-\tilde{y}$-Ebene mit stückweise glattem Rand eineindeutig auf den Bereich $B$ der $x-y$-Ebene abgebildet.
        \item $x=\varphi(x, \tilde{y}), y-\varphi(x, \tilde{y})$ und ihre partiellen Ableitungen erster ordnung seien stetig in $\widetilde{B}$
        \item Im Inneren von $\widetilde{B}$ gelte für die Funktional determinante
        $$
        \operatorname{det}\left[\begin{array}{cc}
        \varphi_{\tilde{x}}\left(\tilde{x}, \tilde{y}\right) & \varphi_{\tilde{y}}(\tilde{x}, \tilde{y}) \\
        \psi_{\tilde{x}}(\tilde{x}, \tilde{y}) & \psi_{\tilde{y}}\left(\tilde{x}, \tilde{y}\right)
        \end{array}\right] \neq 0
        $$
        \item Ist dann die Funktion in $f(x,y)$ in $B$ stetig, so gilt $$
        \iint_B f(x, y) d B=\iint_{\tilde{B}} f\left(\varphi\left(\tilde{x}, \tilde{y}\right), \psi\left(\tilde{x}, \tilde{y}\right)\right) \operatorname{det}\left[\begin{array}{cc}
        \varphi_{\tilde{x}} &\varphi_{\tilde{y}} \\
        \psi_{\tilde{x}} &\psi_{\tilde{y}}
        \end{array}\right] d \tilde{B}
        $$
    \end{itemize}
}
\ex{}{Viertelkreis $\iint_B x y d B$
$$
B=\left\{(x, y): x^2+y^2 \leqslant R^2, x \geqslant 0, y \geqslant 0\right\}
$$
Transformation 
\begin{align*}
&x=r \cos \varphi \quad 0 \leqslant r \leqslant R\\
&y=r \sin \varphi \quad 0 \leqslant \varphi \leqslant \frac{\pi}{2}
\end{align*}
Zuordnung ist eineindeutig.
$$
\begin{aligned}
& x=\varphi(\tilde{x}, \tilde{y})=\varphi(r, \varphi)=r \cos \varphi \\
& y=\psi(\tilde{x}, \tilde{y})=\psi(r, \varphi)=r \sin \varphi
\end{aligned}
$$
$\varphi \psi$ sind stetig
$$
\begin{aligned}
& \varphi_r=\cos \varphi \quad \varphi_{\varphi}=-r \sin \varphi \\
& \psi_r=\sin \varphi \quad \psi_{\psi}=r \cos \varphi \\
&
\end{aligned}
$$
Funktional determinante
$$
\begin{aligned}
\operatorname{det}\left[\begin{array}{cc}
\varphi_r & \varphi_\varphi \\
\psi_r & \psi_\psi
\end{array}\right] & =\operatorname{det}\left[\begin{array}{cc}
\cos \varphi & -r \sin \varphi \\
\sin \varphi & r \cos \varphi
\end{array}\right] \\
& =r \cos ^2 \varphi+r \sin ^2 \varphi \\
& =r
\end{aligned}
$$
ist $\neq 0$ im Inneren von $\widetilde{B}$\newline
$\implies$ Transformationssatz ist anwendbar.}

\section{Rechenregeln für Integrale}
\dfn{}{\textbf{Additivität:}\newline
sind $f,g$ zwei integrierbare Funktionen, so gilt
$$
 \iint_B(f(x, y)+g(x, y)) d B =\int_B f(x, y) d B+\int_B g(x, y) d B
$$
\textbf{Additivität bzgl. der Bereiche:}\newline
Seien $B_1, B_2$ zwei Bereiche ohne gemeinsame innere Punkte, so gilt
$$
\iint_{B, \cup B_2} f(x, y) d B=\int_{B_1} f(x, y) d B+\iint_{B_2} f(x, y) d B
$$
\textbf{Konstanter Faktor:}\newline
Ist $k$ eine reele Zahl, so gilt
$$
\iint_B k f(x, y) d B=k \iint_B f(x, y) d B
$$
\textbf{Monotonie:}
Ist für jeden Punkt $(x, y) \in B$ $f(x, y) \leq g(x, y)$, so gilt
$$
\iint_B f(x, y) d B \leq \iint_B g(x, y) d B
$$
\textbf{Abschätzung:} Ist $f$ über $B$ integrierbar, so auch $|f|$ so gilt
$$
\left|\iint_B f(x, y) d B\right| \leqslant \iint_B|f(x, y)| d B
$$
\textbf{Eingrenzung:}\newline
Ist $m$ die untere, $M$ die obere grenze von $f$ in $B(m \leqslant M)$ und ist $|B|$ der Flächeninhalt von $B$, so gilt
$$
m|B|=\iint_R f(x, y) d B \leq M|B|
$$
\textbf{Mittelwertsatz:}
Wenn $f$ auf $B$ stetig ist, so existiert auf $B$ mindestens eine Stelle $(\xi, \eta)$ mit
$$
\iint_B f(x, y) d B=f(\xi, \eta)|B|
$$
}
\section{Dreifach-Integrale}
\dfn{}{Der Grenzwert
$$
\lim _{\substack{\Delta v_k \rightarrow 0}} \sum_{k=1}^{\infty} f\left(x_k, y_k, z_k\right) \Delta v_k
$$
wird (falls er existiert) alo Dreifach-Integral bezeichnet und duch das Symbol
$$
\iiint_V f(x, y, z) d V
$$
gekennzeichnet.}
\ex{}{Wenn $f:\mathbb{R}^3\to \mathbb{R}$ ist diese sehr schwer vorstellbar und vorallem nicht visualisierbar.\newline
Da der Funktionswert $f(x,y,z)$ nicht mehr eine Koordinate im kartesischen Koordinatensystem darstellt sondern eine gewisse Eigenschaft des Punktes $(x,y,z)$.\newline
In vielen Anwendungen wie in der Physik, könnte dies aber ausgenutzt werden. Sei 
$$
B=\{(x,y,z)\in\mathbb{R}^3\mid x^2+y^2+z^2 = 1\wedge x\geq 0 \wedge y\geq 0 \wedge z\geq 0 \}
$$
\begin{center}
    \begin{tikzpicture}
        % Kugel zeichnen
        \shade[ball color = gray!40, opacity = 0.4] (0,0) circle (2cm);
        \fill[fill=black] (0,0) circle (1pt);
        % Achsen zeichnen
        \draw[thick,->] (0, 0) -- (2.5, 0) node[anchor=north east]{$y$};
        \draw[thick,->] (0, 0) -- (0, 2.5) node[anchor=north west]{$z$};
        \draw[thick,->] (0, 0) -- (0,0,3.533) node[anchor=south]{$x$};
    \end{tikzpicture}
\end{center}

Dann ist der Körper die Kugel und $f(x,y,z)$ kann jetzt eine Eigenschaft über jeden der inneren Punkt beschreiben,
bspw. die Dichte an dieser Stelle und dann wäre das Dreifachintegral gerade die Masse dieser Kugel.\newline
An diesem Beispiel lässt sich auch sehr gut die Formel vorstellen, man Teilt die Kugel in unendlich viele infintisemal $\Delta A = dx\cdot dy\cdot dz$ große Stücke
und berechnet für diese die Dichte und summiert sie dann alle auf. In Abbildung \ref*{fig:Kugel_approximiert} ist dies versuchsweise dargestellt.
\begin{figure}[H]
    \centering
    \includegraphics*[scale=0.3]{Bilder/KugelApproximiert.png}
    \caption{Eine Kugel dargestellt als eine Menge von kleinen Würfeln}
    \label{fig:Kugel_approximiert}
    \end{figure}  
Der Grenzwert dieser Flächen ist dann das Integral
$$
\iiint_A f(x, y,z) d A=\lim _{\substack{\Delta x, \Delta y,\Delta z \rightarrow 0 \\ M, N,L \rightarrow \infty}} \sum_{i=1}^M \sum_{j=1}^N \sum_{k=1}^L f\left(x_{i j k}, y_{i j k},z_{ijk}\right) \Delta A_{i j k}
$$
Der Für uns aber häufig interresante Fall ist wenn $f(x,y,z)=1$, weil dann 
$$
\iiint_A f(x, y,z) d A
$$
gleich dem Volumen des Körpers ist.
}
\thm{Transformation von Variablen}{Die Voraussetzungen seien hier für Transformationsfunktionen 
$x=\varphi(\tilde{x}, \tilde{y}, \tilde{z}),y=\psi(x, \tilde{y}, \tilde{z}), z=\chi(\tilde{x}, \tilde{y}, \tilde{z})$ die selben wie im 2-dimensionalem. 
Ist dann im Inneren des Bereiches $V$ die Funktional-deternmiante
$$
\operatorname{det}\underbrace{\left[\begin{array}{lll}
\frac{\partial \varphi}{\partial \tilde{x}} & \frac{\partial \varphi}{\partial \tilde{y}} & \frac{\partial  \varphi}{\partial \tilde{z}} \\
\frac{\partial \psi}{\partial \tilde{x}} & \frac{\partial \psi}{\partial \tilde{y}} & \frac{\partial \psi}{\partial \tilde{z}} \\
\frac{\partial \chi}{\partial \tilde{x}} & \frac{\partial \chi}{\partial \tilde{y}} & \frac{\partial \chi}{\partial \tilde{z}}
\end{array}\right]}_M \neq 0
$$
so gilt für jede Stetige Funktion $f(x, y, z)$
$$
\iiint_V f(x, y, z) d V =\iiint_{\tilde{V}} f\left(\varphi(\tilde{x}, \tilde{y}, \tilde{z}), \psi(\tilde{x}, \tilde{y}, \tilde{z}), \chi(\tilde{x},\tilde{y}, \tilde{z})\right) \operatorname{det} M d \widetilde{V}
$$
}
\ex{Transformation zu kartesischen Koordinaten}{
    Sei $$
    B=\{(x,y,z)\in\mathbb{R}^3\mid x^2+y^2+z^2 = 1\}
    $$
    Wir wollen das Volumen der Kugel bestimmen, sei also $f(x,y,z)=1$. Wenn wir jetzt 
    $$
    \iiint_V1dV
    $$
    bestimmen erhalten wir direkt das Volumen, ohne einen Wechsel ist dieses Integral aber händisch nicht zu lösen.\newline
    Es wird also ein Wechsel der Variablen hinzu den Polarkoordinaten vorgenommen.
    \begin{figure}[H]
        \centering
        \includegraphics*[scale=0.3]{Bilder/Visualize_Surface_Integral_Polarkoordinates.png}
        \caption{Eine Kugel dargestellt als eine Menge von kleinen Würfeln}
        \label{fig:SurfaceIntegralVisualisiertKugel}
        \end{figure}  
    
    In der Abbildung \ref*{fig:SurfaceIntegralVisualisiertKugel}  wird das Prinzip gezeigt, wie kleine Stücke aus einer Kugel entnommen und anschließend aufsummiert werden, um das Integral zu berechnen.\newline

    Die zentrale Frage ist, warum die Größe eines solchen Stücks genau $r\sin{\vartheta}d\lambda \cdot rd\vartheta\cdot dr$ ist.
    
    Die Höhe des Stücks ist $dr$, was recht intuitiv ist, da sie nicht von den beiden anderen Winkeln abhängt. Eine Seitenkante des Stücks hat die Länge $rd\vartheta$. 
    Man kann sich vorstellen, dass bei einer festen Änderung des Winkels $d\vartheta$ die Länge der Seitenkante in direkter Proportionalität zu $r$ steht - je größer $r$ ist, desto länger wird die Seitenkante, 
    und je kleiner $r$ ist, desto kürzer wird die Kante.\newline
    
    Die letzte Seitenkante ist etwas schwerer zu erkennen. 
    Der Faktor $r$ entsteht auf die gleiche Weise wie bei der vorherigen Seitenkante. 
    Nun muss noch der Faktor $\sin\vartheta$ erklärt werden. Anhand der Abbildung kann man erkennen, dass die Kante von der $z$-Achse zur Seitenkante eine Länge von $r\sin\vartheta$ hat. 
    Bei genauerem Hinsehen ist die Proportionalität dieser Länge zur Länge der Seitenkante erkennbar, woraus sich deren Länge ergibt.\newline

    Wenn diese Transformation erledigt ist, kann jetzt das Integral gelöst werden:
    \begin{align*}
        |V|=\iiint 1 d V & =\int_0^R \int_0^{2 \pi} \int_0^\pi r^2 \sin v d v d \varphi d r \\
        &\text{ Das innerste Integral berechnet einen Halbkreis}\\
        &\text{ im zweiten Integral wird dieser Halbkreis dann einmal vollständig um die $z$ Achse gedreht}\\
        &\text{ im äußersten Integral wird dann für alle $dr$ aufsummiert}\\
        & =\int_0^R r^2 \int_0^{2 \pi}-[\cos v]_0^\pi d p d r \\
        & =\int_0^{R^0} r^2 \int_0^{2 \pi}-((-1)-1) d \varphi d r \\
        & =2 \int_0^R r^2[\varphi]_0^{2 \pi} d r=4 \pi \int_0^R r^2 d r \\
        & =\frac{4}{3} \pi\left[r^3\right]_0^R=\frac{4 \pi R^3}{3}
    \end{align*}
}
\thm{}{
Hat das Dreifachintegral feste Grenzen und lässt sich der Integralrand schreiben als
$$
f(x, y, z)=f_1(x) f_2(y) f_3(z) \text {, }
$$
so gilt
$$
\begin{aligned}
\iiint_V f(x, y, z) d V&=\int_{x_0}^{x_1} \int_{y_0}^{y_1} \int_{z_0}^{z_1} f(x, y, z) d x d y d z \\
& =\int_{x_0}^{x_1} f_1(x) d x \cdot \int_{y_0}^{y_1} f_2(y) d y \int_{z_0}^{z_1} f_3(z) d z \\
&
\end{aligned}
$$}
\ex{}{Bsp: erneut die Berechnung des Volumens der Kugel
$$
\begin{aligned}
|V|=\iiint_V & =\int_0^R r^2 d r \int_0^{2 \pi} d \varphi \cdot \int_0^\pi \sin v d v \\
& =\frac{R^3}{3} \cdot 2 \pi \cdot[-\cos v]_0^\pi \\
& =\frac{R^3}{3} \cdot 2 \pi \cdot(-(-1-1))=\frac{4 \pi R^3}{3}
\end{aligned}
$$}
\chapter{Einführung Numerik}
\dfn{}{Ist $x$ eine reelle Zahl und $\tilde{x}$ ihre Maschinenzahl, dann heißt
$$
|x-\tilde{x}|
$$
der absolute Rundungsfehler und
$$
\left|\frac{x-\tilde{x}}{x}\right|
$$
der relative Rundungsfehler.}
\nt{Ein weiteres Konzept ist das Runden auf Nachkommastellen:
$\pi=3.1415926$ auf $n=4$ dargestellt als 3.1416.\newline
Moderne Computer speichern Realdarstellungszahlen im binären Zahlensystem.

Für die folgenden Beispiele nehmen wir an, wir arbeiten im Dezimalsystem. Eine Zahl $x \in \mathbb{R}$ wird in standardisierter Form dargestellt als
$$x= a\cdot 10^b$$
wobei $a= \pm 0,a_1 a_2 \ldots a_n a_{n+1} \ldots$ mit $0 \leq a_i \leq 9$ und $a_1 \neq 0$ die Mantisse ist und $b$ der Exponent.
$$
a^{\prime}= \begin{cases}0.a_1a_2 \dots a_n \quad 0 \leq a_{n+1} \leq 4 \\ 0.a_1a_2 \dots a_n+10^{-n}: a_{n+1} \geq 5\end{cases}
$$
}


\chapter{Quadratur (Numerische Integration)}
\qs{}{
    \textbf{Gegeben:} Stetige Funktion über begrenztem Intervall
\[
f:[a, b] \rightarrow \mathbb{R}
\]
\textbf{Gesucht:} Bestimmtes Integral
\[
I=\int_a^b f(x) \, dx
\]
}
\nt{\begin{itemize}
    \item $f$ stetig $\Rightarrow$ I existiert
    \item "Quadratur" Integral als Fläche zwischen Kurve
    \item Vorzeichen sind zu betrachten, falls $f$ die $x$-Achse schneidet
    \end{itemize}}
\ex{Analytische Lösung bekannt}{
    $$
f(x)=x \cdot e^{x} \quad, a=0, b=1
$$
\begin{figure}[H]
    \centering
    \includegraphics*[scale=0.5]{Bilder/Int_xetox.png}
    \end{figure}
}
\ex{Keine Analytische Lösung bekannt}{
    $$f(x)=e^{-x^{2}} \quad a=-1, b=1$$
    \begin{figure}[H]
        \centering
        \includegraphics*[scale=0.5]{Bilder/BellCurveInt.png}
    \end{figure}
}
\ex{Keine geschlossene Lösung angebbar}{
    $$
f(x)=\frac{1}{\ln (x)}, a=2, b=3\quad\footnote{\url{https://mathworld.wolfram.com/LogarithmicIntegral.html}}
$$
\begin{figure}[H]
    \centering
    \includegraphics*[scale=0.5]{Bilder/InrLogX.png}
\end{figure}
}
\nt{\begin{itemize}
    \item Existiert eine geschlossene Lösung, so ist
    \[
    I=F(b)-F(a)
    \]
    (nutzen wir lieber zur Veranschaulichung)
    \item Ermittlung (näherungsweise) numerisch
    \item Fehler der Quadraturformel ist Abweichung vom exakten Wert
    \end{itemize}}
\nt{\begin{minipage}[t]{0.49\textwidth}
    \begin{figure}[H]
        \centering
        \includegraphics*[scale=0.5]{Bilder/IntTrapze.png}
    \end{figure}
    $$
I =\int_{a}^b f(x) d x \approx \frac{f(a)+f(b)}{2}(b-a)
$$
    \end{minipage}
    \begin{minipage}[t]{0.5\textwidth}
        \begin{figure}[H]
            \centering
            \includegraphics*[scale=0.5]{Bilder/InrRechteck.png}
        \end{figure}
        $$
        I =\int_{a}^b f(x) d x \approx f\left(\frac{a+b}{2}\right)(b-a)
        $$
    \end{minipage}
    Zerlege das Intervall $[a, b]$ in $N$ genügend kleine Teilintervalle
\[
a=x_0<x_1<\ldots<x_N=b
\]
$x_i$... Stützstellen / Knoten

Wegen Additivität
\[
\int_a^b f(x) dx=\sum_{j=0}^{N-1}\left(\int_{x_j}^{x_{j+1}} f(x) dx\right)
\]
Betrachten wir das Teilintervall und führen die Schrittweite $h_j:=x_{j+1}-x_j$ ein. Sei $t:=\frac{\left(x-x_j\right)}{h_j}$, dann gilt
$$
x=x_j+t\cdot h_j \implies \frac{dx}{dt} = h_j
$$
$$dx = h_jdt$$
durch Substitution erhält man
\[
\int_{x_j}^{x_{j+1}} f(x) dx=h_j\int_0^1 f(x_j+t h_j) dt
\]
Sei $g(t)=f\left(x_j+t h_j\right)$, ist
\[
I=\int_0^1 g(t) dt
\]    
das neue Integral. \newline
Wenn als Näherungsmethode das Rechteck gewählt wird, erhält man:
$$
\int_0^1 g(t) d t \approx g\left(\frac{1}{2}\right)=(1-0) \cdot g\left(\frac{1}{2}\right).
$$   
Wenn als Näherungsmethode das Trapez gewählt wird, erhält man:
$$
\int_0^1 g(t) d t \approx \frac{1}{2}(g(\dot{0})+g(1)).
$$ 
Wenn man als Näherungsmethode eine Parabel wählt die $g(t)$, dann kann diese Parabel dargestellt werden als
$$
P(t)=at^2+bt+c
$$
mit den Bediengungen 
$$
g(0) = c\quad g(0.5)=\frac{a}{4}+\frac{b}{2}+c \quad g(1)=a+b+c
$$
Wenn man dieses Gleichungssystem löst erhält man
$$
a=2\left(g(0)-2 g\left(\frac{1}{2}\right)+g(1)\right) \text { und } b=-3 g(0)+4 g\left(\frac{1}{2}\right)-g(1) \text { und } c=g(0)
$$
Wenn das jetzt integriert wird
$$
\int_{0}^{1} 2\left(g(0)-2 g\left(\frac{1}{2}\right)+g(1)\right)t^2+(-3 g(0)+4 g\left(\frac{1}{2}\right)-g(1))t+g(0) dt = \frac{1}{6}\left(g(0)+4 g\left(\frac{1}{2}\right)+g(1)\right)
$$
Daraus folgt:
$$
\int_0^1 g(t) d t \approx \frac{1}{6}\left(g(0)+4 g\left(\frac{1}{2}\right)+g(1)\right)
$$}
\section{Newton-Cotes-Quadratur-Formeln}
\nt{Wir führen $s$ äquadistante Stützstellen der Form 
$$
c_i=\frac{i-1}{s-1}
$$
ein, mit $i\in\{1,\dots,s\}$. Daraus folgen $s$ Punktepaare $(c_i,g(c_i))$, durch diese wird jetzt ein polynom des Grades $s-1$ gelegt. Mit diesen Polynom kann dann das Integral von $g$ approximiert werden:
}
\dfn{Approximation von $g$ als Summe}{$$
\int_0^1 g(t) d t \approx \int_0^1 g(t) d t=\sum_{i=1}^s b_i g\left(c_i\right)
$$}
\nt{Die Koeffizienten $b_i$ können bspw. über das lösen des Gleichungssystems und folgendes Integrieren erhalten werden. Wie bereits oben für $s=3$ gezeigt.}

\dfn{Ordnung einer Quadraturformel}{Eine Quadraturformel $\sum_{i=1}^s b_i g\left(c_i\right)$,
mit Stützstellen $c_i$ und Gewichten $b_i$ ist von der Ordnung $p$, falls
für alle Polynome $q \in \Pi_{p-1}(\mathbb{R})$ gilt
$$
\int_0^1 q(t) d t=\sum_{i=1}^S b_i g\left(c_i\right)
$$
und für ein Polynom $q \in \pi_p(\mathbb{R})$ gilt
$$
\int_0^1 q(t) d t\neq\sum_{i=1}^s b_i g\left(c_i\right)
$$}
\nt{Per Konstruktion der Quadraturformeln mit Polynomen vom Grad $s-1$ ist die Ordnung der Newton-Cotes Formeln mindestens $s$.}
\thm{}{Die Quadraturformel $\sum_{i=1}^s b_i g\left(c_i\right)$ ist von der Ordnung $p$ genau dann, wenn für alle $m \in\left\{1, \ldots, p\right\}$ gilt
$$
\sum_{i=1}^S b_i c_i^{m-1}=\frac{1}{m}
$$}
\ex{Ordnung der Simpson Regel}{
\begin{align*}
m=1: & \sum_{i=1}^3 b_i=\frac{1}{6}+\frac{4}{6}+\frac{1}{6}=1=\frac{1}{1} \\
m=2: & \sum_{i=1}^3 b_i c_i=\frac{1}{6} \cdot 0+\frac{4}{6} \cdot \frac{1}{2}+\frac{1}{6} \cdot 1=\frac{1}{2} \\
m=3: & \sum_{i=1}^3 b_i c_i^2=\frac{1}{6} \cdot 0^2+\frac{4}{6} \cdot\left(\frac{1}{2}\right)^2+\frac{1}{6} \cdot 1^2=\frac{1}{3}
\end{align*}
Sogar für $m=4$ ist die Bedingung erfüllt
$$
\sum_{i=1}^3 b_i c_i^3=\frac{1}{6} \cdot 0^3+\frac{4}{6} \cdot\left(\frac{1}{2}\right)^3+\frac{1}{6} \cdot 1^3=\frac{1}{4}
$$
Aber für $m=5$
$$
\sum_{i=1}^3 b_i c_i^4=\frac{1}{6} \cdot 0^4+\frac{4}{6} \cdot\left(\frac{1}{2}\right)^4+\frac{1}{6} \cdot 1^4=\frac{5}{24} \neq \frac{1}{5}
$$
ist die Bedingung nicht erfüllt,
somit ist die Simpson Regel vor der Ordnung 4.
}
\section{Symmetrische Quadraturformeln}
\dfn{}{Enie Quadraturformel heißt symmetrisch, falls
$$
\begin{aligned}
& c_i=1-c_{s-i+1} \text { und } \\
& b_i=b_{s-i+1}
\end{aligned}
$$
erfüllt ist.}
\nt{Äquivalent zur intuitiven Vorstellung, dass die Gewichte und die Abstände der Stützstellen von vorne rechts nach links equivalent zu von links nach rechts sind.}
\thm{}{Eine symmetrische Quadraturformel ist immer von gerader Ordnung.}
\ex{}{Aus diesem Theorem lässt sich folgt der vorher gesehene Fakt, dass Simpson Regel, obwohl sie $s=3$ hat eine Ordnung 4 besitzt.}


\chapter{Quadraturfehler und Gausformel}
\thm{}{Seien Stützstellen $c_1,\dots,c_s$ mit $c_i\neq c_j$ gegeben. Dann existieren Gewichte $b_1,\dots,b_s$ so, dass die }
\end{document}
